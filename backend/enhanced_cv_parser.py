#!/usr/bin/env python3
"""
üöÄ Enhanced CV Parser - Optimisation du Parser Existant
=======================================================

Am√©liore le parser CV/FDP existant avec :
- Prompts optimis√©s pour >90% qualit√©
- Validation multi-niveaux
- Retry logic intelligent
- Compatible avec l'architecture existante

Author: Nextvision Team
Version: 3.0 - Real Integration
"""

import json
import re
import time
import openai
import os
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum

# Import de l'optimiseur
from cv_parser_optimizer import CVParserOptimizer, CVExtractionResult, DataQuality

class EnhancedCVParser:
    """Parser CV am√©lior√© qui s'int√®gre avec le syst√®me existant"""
    
    def __init__(self, api_key: str = None):
        self.optimizer = CVParserOptimizer()
        
        # Utiliser la cl√© API existante ou celle fournie
        self.api_key = api_key or os.environ.get('OPENAI_API_KEY')
        if self.api_key:
            openai.api_key = self.api_key
        
        # Configuration OpenAI optimis√©e
        self.model = os.environ.get('MODEL', 'gpt-3.5-turbo')
        self.temperature = 0.2  # Plus bas pour plus de pr√©cision
        self.max_tokens = 2500   # Plus √©lev√© pour les CVs complexes
    
    def extract_cv_info_with_enhanced_gpt(self, cv_text: str, max_retries: int = 3) -> Dict[str, Any]:
        """
        Parse CV avec GPT optimis√© - Compatible avec l'API existante
        
        Cette fonction remplace/am√©liore la fonction existante analyze_with_gpt()
        """
        
        if not self.api_key:
            raise Exception("Cl√© API OpenAI non configur√©e")
        
        # Limiter la taille du contenu
        if len(cv_text) > 20000:
            cv_text = cv_text[:20000] + "...[contenu tronqu√©]"
        
        # Tentatives avec retry logic
        for attempt in range(1, max_retries + 1):
            try:
                # G√©n√©rer le prompt selon la tentative
                if attempt == 1:
                    prompt = self.optimizer.get_optimized_prompt(cv_text)
                else:
                    # Retry avec prompt adaptatif
                    prompt = self.optimizer.get_retry_prompt(cv_text, previous_result, attempt)
                
                # Appel OpenAI optimis√©
                response = openai.ChatCompletion.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system", 
                            "content": "Tu es un expert en extraction de donn√©es CV avec 15 ans d'exp√©rience. Tu es extr√™mement pr√©cis et ne jamais inventer d'informations."
                        },
                        {
                            "role": "user", 
                            "content": prompt
                        }
                    ],
                    temperature=self.temperature,
                    max_tokens=self.max_tokens
                )
                
                # Extraire et parser la r√©ponse
                result_text = response.choices[0].message.content.strip()
                raw_result = self.parse_gpt_response(result_text)
                
                # Am√©liorer l'extraction avec l'optimiseur
                enhanced_result = self.optimizer.enhance_extraction(raw_result)
                
                # V√©rifier si retry n√©cessaire
                if not self.optimizer.should_retry(enhanced_result, attempt):
                    # Convertir en format compatible avec l'API existante
                    return self.convert_to_api_format(enhanced_result)
                
                previous_result = enhanced_result
                
            except Exception as e:
                if attempt == max_retries:
                    # En cas d'√©chec final, retourner un r√©sultat minimal
                    return {
                        "success": False,
                        "error": f"√âchec apr√®s {max_retries} tentatives: {str(e)}",
                        "quality_score": 0,
                        "data": {}
                    }
                
                print(f"Tentative {attempt} √©chou√©e: {e}")
                time.sleep(1)  # Pause avant retry
        
        # Ne devrait pas arriver
        return {"success": False, "error": "Erreur inattendue"}
    
    def parse_gpt_response(self, response_text: str) -> Dict[str, Any]:
        """Parse la r√©ponse GPT en JSON"""
        
        try:
            # Essayer de parser directement
            return json.loads(response_text)
        except json.JSONDecodeError:
            # Extraire le JSON du markdown si n√©cessaire
            json_pattern = r'```json\s*(.*?)\s*```'
            match = re.search(json_pattern, response_text, re.DOTALL)
            
            if match:
                return json.loads(match.group(1))
            
            # Derni√®re tentative : extraire JSON brut
            json_pattern2 = r'\{.*\}'
            match2 = re.search(json_pattern2, response_text, re.DOTALL)
            
            if match2:
                return json.loads(match2.group(0))
            
            # Si tout √©choue, retourner structure vide
            return {}
    
    def convert_to_api_format(self, enhanced_result: CVExtractionResult) -> Dict[str, Any]:
        """Convertit le r√©sultat optimis√© au format API existant"""
        
        # Format compatible avec ton API existante
        api_result = {
            "success": enhanced_result.quality_score >= 60,  # Seuil minimum
            "quality_score": enhanced_result.quality_score,
            "quality_level": enhanced_result.quality_level.value,
            "confidence": enhanced_result.confidence_score,
            "missing_fields": enhanced_result.missing_fields,
            
            # Donn√©es principales
            "data": {
                # Informations personnelles
                "nom": enhanced_result.nom,
                "prenom": enhanced_result.prenom,
                "email": enhanced_result.email,
                "telephone": enhanced_result.telephone,
                "adresse": enhanced_result.adresse,
                
                # Exp√©rience
                "annees_experience": enhanced_result.annees_experience,
                "poste_actuel": enhanced_result.poste_actuel,
                "entreprise_actuelle": enhanced_result.entreprise_actuelle,
                "postes_precedents": enhanced_result.postes_precedents,
                "entreprises_precedentes": enhanced_result.entreprises_precedentes,
                
                # Comp√©tences
                "competences_techniques": enhanced_result.competences_techniques,
                "competences_transversales": enhanced_result.competences_transversales,
                "technologies": enhanced_result.technologies,
                "certifications": enhanced_result.certifications,
                
                # Formation
                "niveau_formation": enhanced_result.niveau_formation,
                "domaine_formation": enhanced_result.domaine_formation,
                "etablissement": enhanced_result.etablissement,
                "diplomes": enhanced_result.diplomes,
                
                # Autres
                "langues": enhanced_result.langues,
                "objectif_professionnel": enhanced_result.objectif_professionnel,
                "resume_profil": enhanced_result.resume_profil,
                "secteurs_experience": enhanced_result.secteurs_experience
            }
        }
        
        return api_result
    
    def analyze_with_gpt(self, text: str) -> Dict[str, Any]:
        """
        Fonction de compatibilit√© avec l'API existante
        
        Cette fonction remplace directement analyze_with_gpt() dans parse_fdp_gpt.py
        """
        return self.extract_cv_info_with_enhanced_gpt(text)

# ================================
# FONCTIONS DE COMPATIBILIT√â API
# ================================

def create_enhanced_parser() -> EnhancedCVParser:
    """Cr√©e une instance du parser am√©lior√©"""
    return EnhancedCVParser()

def enhanced_analyze_with_gpt(text: str) -> Dict[str, Any]:
    """
    Fonction de remplacement pour analyze_with_gpt() existante
    
    Usage: Remplacer l'import dans gpt_parser.py par cette fonction
    """
    parser = create_enhanced_parser()
    return parser.analyze_with_gpt(text)

# ================================
# INT√âGRATION AVEC FLASK/FASTAPI
# ================================

def enhance_existing_api():
    """
    Guide d'int√©gration avec l'API existante
    
    1. Dans gpt_parser.py, remplacer :
       from parse_fdp_gpt import analyze_with_gpt
       
       Par :
       from enhanced_cv_parser import enhanced_analyze_with_gpt as analyze_with_gpt
    
    2. Ou modifier parse_fdp_gpt.py pour utiliser cette classe
    """
    return {
        "integration_steps": [
            "1. Backup du parser existant",
            "2. Remplacer analyze_with_gpt() par enhanced_analyze_with_gpt()",
            "3. Tester avec quelques CVs",
            "4. Mesurer l'am√©lioration de qualit√©",
            "5. D√©ployer en production"
        ]
    }

# ================================
# TESTS D'INT√âGRATION
# ================================

def test_integration_with_real_cv(cv_file_path: str) -> Dict[str, Any]:
    """Teste l'int√©gration avec un vrai CV"""
    
    parser = create_enhanced_parser()
    
    # Simuler l'extraction de texte (comme fait dans ton syst√®me)
    with open(cv_file_path, 'r', encoding='utf-8') as f:
        cv_text = f.read()
    
    start_time = time.time()
    
    try:
        # Parser avec le syst√®me am√©lior√©
        result = parser.analyze_with_gpt(cv_text)
        processing_time = time.time() - start_time
        
        return {
            "test_success": True,
            "processing_time": processing_time,
            "quality_score": result.get("quality_score", 0),
            "api_compatible": "data" in result,
            "result": result
        }
        
    except Exception as e:
        return {
            "test_success": False,
            "error": str(e),
            "processing_time": time.time() - start_time
        }

if __name__ == "__main__":
    print("üöÄ === ENHANCED CV PARSER - INT√âGRATION R√âELLE ===")
    print("Parser optimis√© compatible avec l'architecture Commitment- existante")
    print()
    
    # Test de base
    parser = create_enhanced_parser()
    
    cv_test = """
    Jean MARTIN
    D√©veloppeur Full-Stack
    jean.martin@email.com
    06 12 34 56 78
    
    EXP√âRIENCE:
    2020-2024: D√©veloppeur Senior - TechCorp
    2018-2020: D√©veloppeur Python - StartupXYZ
    
    COMP√âTENCES:
    - Python, Django, Flask
    - React, JavaScript
    - Docker, PostgreSQL
    """
    
    print("üß™ Test avec CV exemple...")
    result = parser.analyze_with_gpt(cv_test)
    
    print(f"‚úÖ Success: {result.get('success', False)}")
    print(f"üìä Qualit√©: {result.get('quality_score', 0):.1f}%")
    print(f"üéØ Compatible API: {'data' in result}")
    
    print("\nüí° === INT√âGRATION ===")
    print("Pour int√©grer dans ton syst√®me existant :")
    print("1. Copier ce fichier dans backend/")
    print("2. Dans gpt_parser.py, remplacer l'import analyze_with_gpt")
    print("3. Tester avec tes CVs r√©els")
    print("4. Mesurer l'am√©lioration vs 54.5% baseline")
