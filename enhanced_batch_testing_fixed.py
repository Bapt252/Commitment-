#!/usr/bin/env python3
"""
üß™ SuperSmartMatch V2.1 - Tests Massifs et Benchmarking (VERSION CORRIG√âE)
Script avanc√© pour tester et optimiser le syst√®me en lot
Supports: PDF, DOC, DOCX, PNG, JPG, JPEG

CORRECTIONS V2.1.1:
‚úÖ Gestion correcte des espaces dans les noms de dossiers
‚úÖ Am√©lioration de la robustesse du parsing des chemins
‚úÖ Meilleure gestion des erreurs de fichiers
"""

import requests
import json
import os
import time
import pandas as pd
from pathlib import Path
from typing import List, Dict, Tuple
import statistics
from datetime import datetime
import argparse
import concurrent.futures
from threading import Lock
import urllib.parse

class EnhancedTestSuite:
    
    def __init__(self, base_url="http://localhost:5055"):
        self.base_url = base_url
        self.results = []
        self.stats = {}
        self.lock = Lock()
        
        # Formats de fichiers support√©s
        self.supported_cv_formats = {'.pdf', '.doc', '.docx', '.png', '.jpg', '.jpeg'}
        self.supported_job_formats = {'.pdf', '.doc', '.docx', '.png', '.jpg', '.jpeg'}
        
    def normalize_path(self, folder_path: str) -> Path:
        """Normalise un chemin en g√©rant correctement les espaces et la tilde"""
        # √âtape 1: Expansion de la tilde (~)
        expanded_path = os.path.expanduser(folder_path)
        
        # √âtape 2: R√©solution du chemin absolu
        absolute_path = os.path.abspath(expanded_path)
        
        # √âtape 3: Conversion en objet Path pour une manipulation robuste
        path_obj = Path(absolute_path)
        
        print(f"üìÅ Normalisation chemin:")
        print(f"   Input: {folder_path}")
        print(f"   Expanded: {expanded_path}")
        print(f"   Absolute: {absolute_path}")
        print(f"   Final Path: {path_obj}")
        print(f"   Exists: {path_obj.exists()}")
        
        return path_obj
        
    def find_files_in_folder(self, folder_path: str, file_types: set) -> List[Path]:
        """Trouve tous les fichiers support√©s dans un dossier (version corrig√©e)"""
        try:
            folder = self.normalize_path(folder_path)
            found_files = []
            
            if not folder.exists():
                print(f"‚ö†Ô∏è  Dossier non trouv√©: {folder}")
                # Tentative de diagnostic
                print(f"üìä Diagnostic:")
                print(f"   - Dossier parent: {folder.parent}")
                print(f"   - Parent existe: {folder.parent.exists()}")
                if folder.parent.exists():
                    print(f"   - Contenu parent: {list(folder.parent.iterdir())}")
                return []
            
            print(f"‚úÖ Dossier trouv√©: {folder}")
            
            # M√©thode robuste pour trouver les fichiers
            for file_type in file_types:
                try:
                    # Utilise rglob pour √™tre plus permissif
                    files = list(folder.rglob(f"*{file_type}"))
                    found_files.extend(files)
                    print(f"   üìÑ {file_type}: {len(files)} fichiers")
                except Exception as e:
                    print(f"   ‚ùå Erreur pour {file_type}: {e}")
            
            # √âliminer les doublons et trier
            found_files = sorted(list(set(found_files)))
            print(f"üìä Total: {len(found_files)} fichiers trouv√©s")
            
            return found_files
            
        except Exception as e:
            print(f"‚ùå Erreur dans find_files_in_folder: {e}")
            return []
    
    def analyze_folder_content(self, folder_path: str) -> Dict:
        """Analyse le contenu d'un dossier (version corrig√©e)"""
        try:
            folder = self.normalize_path(folder_path)
            
            if not folder.exists():
                return {
                    'exists': False,
                    'path': str(folder),
                    'error': f'Dossier non trouv√©: {folder}',
                    'parent_exists': folder.parent.exists(),
                    'parent_content': list(folder.parent.iterdir()) if folder.parent.exists() else []
                }
            
            files_by_type = {}
            total_files = 0
            
            for item in folder.iterdir():
                if item.is_file():
                    ext = item.suffix.lower()
                    if ext not in files_by_type:
                        files_by_type[ext] = []
                    files_by_type[ext].append(item.name)
                    total_files += 1
            
            supported_files = []
            all_supported = self.supported_cv_formats.union(self.supported_job_formats)
            
            for ext in all_supported:
                if ext in files_by_type:
                    supported_files.extend([f for f in files_by_type[ext]])
            
            return {
                'exists': True,
                'path': str(folder),
                'total_files': total_files,
                'files_by_type': files_by_type,
                'supported_files': supported_files,
                'supported_count': len(supported_files)
            }
            
        except Exception as e:
            return {
                'exists': False,
                'path': folder_path,
                'error': f'Erreur analyse dossier: {str(e)}'
            }
    
    def test_cv_parsing_quality(self, cv_folder: str) -> Dict:
        """√âvalue la qualit√© du parsing des CV (version am√©lior√©e)"""
        cv_files = self.find_files_in_folder(cv_folder, self.supported_cv_formats)
        parsing_results = []
        
        print(f"üîç Test qualit√© parsing sur {len(cv_files)} fichiers...")
        
        # Afficher les formats trouv√©s
        formats_found = {}
        for cv_file in cv_files:
            ext = cv_file.suffix.lower()
            formats_found[ext] = formats_found.get(ext, 0) + 1
        
        if formats_found:
            print(f"   üìÑ Formats d√©tect√©s: {dict(formats_found)}")
        
        for i, cv_file in enumerate(cv_files[:20]):  # Limiter √† 20 pour les tests
            try:
                print(f"   üìÑ Test {i+1}/20: {cv_file.name}")
                
                with open(cv_file, 'rb') as f:
                    response = requests.post(
                        "http://localhost:5051/api/parse-cv/",
                        files={'file': f},
                        data={'force_refresh': 'true'},
                        timeout=30
                    )
                
                if response.ok:
                    cv_data = response.json()
                    quality_score = self.evaluate_cv_quality(cv_data)
                    text_length = len(cv_data.get('raw_text', ''))
                    
                    parsing_results.append({
                        'file': cv_file.name,
                        'format': cv_file.suffix.lower(),
                        'quality_score': quality_score,
                        'text_length': text_length,
                        'missions_count': len(cv_data.get('professional_experience', [{}])[0].get('missions', [])),
                        'skills_count': len(cv_data.get('technical_skills', []) + cv_data.get('soft_skills', [])),
                        'status': 'success'
                    })
                    
                    # Diagnostic sp√©cial pour BATU Sam.pdf
                    if 'BATU Sam' in cv_file.name or 'batu sam' in cv_file.name.lower():
                        print(f"   üéØ DIAGNOSTIC BATU SAM:")
                        print(f"      - Texte extrait: {text_length} caract√®res")
                        print(f"      - Score qualit√©: {quality_score:.1f}%")
                        print(f"      - Nom candidat: {cv_data.get('candidate_name', 'NON TROUV√â')}")
                        print(f"      - Missions: {len(cv_data.get('professional_experience', [{}])[0].get('missions', []))}")
                        if text_length < 100:
                            print(f"      ‚ö†Ô∏è  PROBL√àME: Tr√®s peu de texte extrait!")
                else:
                    print(f"   ‚ùå Erreur HTTP {response.status_code}")
                    parsing_results.append({
                        'file': cv_file.name,
                        'format': cv_file.suffix.lower(),
                        'status': 'error',
                        'error_code': response.status_code
                    })
                    
            except Exception as e:
                print(f"   ‚ùå Exception: {str(e)}")
                parsing_results.append({
                    'file': cv_file.name,
                    'format': cv_file.suffix.lower(),
                    'status': 'exception',
                    'error': str(e)
                })
        
        return {
            'total_files': len(cv_files),
            'tested_files': len(parsing_results),
            'successful_parses': len([r for r in parsing_results if r.get('status') == 'success']),
            'average_quality': statistics.mean([r.get('quality_score', 0) for r in parsing_results if r.get('quality_score')]) if parsing_results else 0,
            'formats_found': formats_found,
            'detailed_results': parsing_results
        }
    
    def evaluate_cv_quality(self, cv_data: Dict) -> float:
        """√âvalue la qualit√© d'un CV pars√©"""
        score = 0
        
        # Nom du candidat (20%)
        if cv_data.get('candidate_name'):
            score += 20
            
        # Exp√©rience professionnelle (30%)
        exp = cv_data.get('professional_experience', [])
        if exp and len(exp) > 0:
            score += 15
            missions = exp[0].get('missions', [])
            if missions and len(missions) >= 3:
                score += 15
                
        # Comp√©tences (25%)
        tech_skills = cv_data.get('technical_skills', [])
        soft_skills = cv_data.get('soft_skills', [])
        if tech_skills:
            score += 15
        if soft_skills:
            score += 10
            
        # Texte extrait (15%)
        raw_text = cv_data.get('raw_text', '')
        if len(raw_text) > 500:
            score += 15
        elif len(raw_text) > 200:
            score += 10
            
        # Formation (10%)
        if cv_data.get('education'):
            score += 10
            
        return min(score, 100)
    
    def test_problematic_file(self, file_path: str) -> Dict:
        """Test sp√©cifique pour un fichier probl√©matique (version am√©lior√©e)"""
        try:
            file_path = self.normalize_path(file_path)
            
            if not file_path.exists():
                return {
                    'file': file_path.name,
                    'status': 'file_not_found',
                    'error': f'Fichier non trouv√©: {file_path}',
                    'path_tried': str(file_path),
                    'parent_exists': file_path.parent.exists(),
                    'parent_content': list(file_path.parent.iterdir()) if file_path.parent.exists() else []
                }
            
            # V√©rifier le format
            file_format = file_path.suffix.lower()
            if file_format not in self.supported_cv_formats:
                return {
                    'file': file_path.name,
                    'format': file_format,
                    'status': 'unsupported_format',
                    'error': f'Format non support√©: {file_format}',
                    'supported_formats': list(self.supported_cv_formats)
                }
            
            print(f"üîç Test sp√©cifique: {file_path.name}")
            print(f"   üìÅ Chemin: {file_path}")
            print(f"   üìä Taille: {file_path.stat().st_size} bytes")
            
            # Test parsing CV
            with open(file_path, 'rb') as f:
                cv_response = requests.post(
                    "http://localhost:5051/api/parse-cv/",
                    files={'file': f},
                    data={'force_refresh': 'true'},
                    timeout=30
                )
            
            if not cv_response.ok:
                return {
                    'file': file_path.name,
                    'format': file_format,
                    'status': 'parsing_error',
                    'error_code': cv_response.status_code,
                    'error_message': cv_response.text[:200] if cv_response.text else 'Erreur inconnue'
                }
            
            cv_data = cv_response.json()
            
            # Analyse d√©taill√©e
            analysis = {
                'file': file_path.name,
                'format': file_format,
                'status': 'success',
                'file_size_bytes': file_path.stat().st_size,
                'text_extraction': {
                    'raw_text_length': len(cv_data.get('raw_text', '')),
                    'raw_text_preview': cv_data.get('raw_text', '')[:200] + '...' if cv_data.get('raw_text') else '',
                    'quality_score': self.evaluate_cv_quality(cv_data)
                },
                'content_analysis': {
                    'candidate_name': cv_data.get('candidate_name', 'Non trouv√©'),
                    'professional_experience_count': len(cv_data.get('professional_experience', [])),
                    'missions_count': len(cv_data.get('professional_experience', [{}])[0].get('missions', [])) if cv_data.get('professional_experience') else 0,
                    'technical_skills_count': len(cv_data.get('technical_skills', [])),
                    'soft_skills_count': len(cv_data.get('soft_skills', []))
                },
                'raw_parsing_response': cv_data,  # Pour diagnostic approfondi
                'potential_issues': []
            }
            
            # D√©tection des probl√®mes
            if analysis['text_extraction']['raw_text_length'] < 50:
                analysis['potential_issues'].append({
                    'type': 'critical_low_text_extraction',
                    'description': f"CRITIQUE: Tr√®s peu de texte extrait ({analysis['text_extraction']['raw_text_length']} caract√®res)",
                    'recommendation': f"Le fichier {file_format} ne peut pas √™tre lu correctement. V√©rifier l'int√©grit√© du fichier ou essayer un autre format."
                })
            elif analysis['text_extraction']['raw_text_length'] < 200:
                analysis['potential_issues'].append({
                    'type': 'low_text_extraction',
                    'description': f"Peu de texte extrait ({analysis['text_extraction']['raw_text_length']} caract√®res)",
                    'recommendation': f"V√©rifier le format {file_format} ou les permissions de lecture"
                })
            
            if analysis['content_analysis']['missions_count'] == 0:
                analysis['potential_issues'].append({
                    'type': 'no_missions_found',
                    'description': "Aucune mission d√©tect√©e",
                    'recommendation': "V√©rifier le parsing des exp√©riences professionnelles"
                })
            
            if analysis['content_analysis']['candidate_name'] == 'Non trouv√©':
                analysis['potential_issues'].append({
                    'type': 'no_candidate_name',
                    'description': "Nom du candidat non d√©tect√©",
                    'recommendation': "V√©rifier la structure du document"
                })
            
            return analysis
            
        except Exception as e:
            return {
                'file': Path(file_path).name if file_path else 'unknown',
                'status': 'exception',
                'error': str(e)
            }

    def discover_files(self, cv_folder: str, job_folder: str) -> Dict:
        """D√©couvre et analyse les fichiers dans les dossiers (version am√©lior√©e)"""
        print("üîç D√âCOUVERTE DES FICHIERS (Version Corrig√©e)")
        print("="*50)
        
        cv_analysis = self.analyze_folder_content(cv_folder)
        job_analysis = self.analyze_folder_content(job_folder)
        
        print(f"üìÅ Dossier CV: {cv_analysis['path']}")
        if cv_analysis['exists']:
            print(f"   ‚úÖ {cv_analysis['total_files']} fichiers trouv√©s")
            print(f"   üìÑ {cv_analysis['supported_count']} fichiers support√©s")
            print(f"   üìä Types: {dict(cv_analysis['files_by_type'])}")
        else:
            print(f"   ‚ùå {cv_analysis['error']}")
            if 'parent_exists' in cv_analysis and cv_analysis['parent_exists']:
                print(f"   üìÅ Parent existe, contenu: {cv_analysis.get('parent_content', [])}")
        
        print(f"\nüìÅ Dossier Jobs: {job_analysis['path']}")
        if job_analysis['exists']:
            print(f"   ‚úÖ {job_analysis['total_files']} fichiers trouv√©s")
            print(f"   üìÑ {job_analysis['supported_count']} fichiers support√©s")
            print(f"   üìä Types: {dict(job_analysis['files_by_type'])}")
        else:
            print(f"   ‚ùå {job_analysis['error']}")
            if 'parent_exists' in job_analysis and job_analysis['parent_exists']:
                print(f"   üìÅ Parent existe, contenu: {job_analysis.get('parent_content', [])}")
        
        return {
            'cv_folder': cv_analysis,
            'job_folder': job_analysis
        }

def main():
    parser = argparse.ArgumentParser(description='Tests massifs SuperSmartMatch V2.1 - Support multi-formats (VERSION CORRIG√âE)')
    parser.add_argument('--cv-folder', default='~/Desktop/CV TEST', help='Dossier des CV (gestion espaces corrig√©e)')
    parser.add_argument('--job-folder', default='~/Desktop/FDP TEST', help='Dossier des Jobs (gestion espaces corrig√©e)')
    parser.add_argument('--max-tests', type=int, default=50, help='Nombre max de combinaisons')
    parser.add_argument('--output', help='Fichier de sortie du rapport')
    parser.add_argument('--parsing-quality', action='store_true', help='Test qualit√© parsing')
    parser.add_argument('--test-file', help='Test un fichier sp√©cifique')
    parser.add_argument('--discover', action='store_true', help='D√©couvrir les fichiers dans les dossiers')
    
    args = parser.parse_args()
    
    test_suite = EnhancedTestSuite()
    
    print("üöÄ SuperSmartMatch V2.1 - Suite de Tests Avanc√©s (VERSION CORRIG√âE)")
    print("="*70)
    print("üîß CORRECTIONS APPORT√âES:")
    print("   ‚úÖ Gestion correcte des espaces dans les noms de dossiers")
    print("   ‚úÖ Am√©lioration de la robustesse du parsing des chemins")
    print("   ‚úÖ Diagnostic am√©lior√© pour fichiers probl√©matiques")
    print("   ‚úÖ Meilleure gestion des erreurs de fichiers")
    print("üìÑ Formats support√©s: PDF, DOC, DOCX, PNG, JPG, JPEG")
    print("="*70)
    
    # D√©couverte des fichiers
    discovery = test_suite.discover_files(args.cv_folder, args.job_folder)
    
    # Test d'un fichier sp√©cifique
    if args.test_file:
        print(f"\nüîç TEST FICHIER SP√âCIFIQUE: {args.test_file}")
        print("-" * 50)
        file_analysis = test_suite.test_problematic_file(args.test_file)
        print(f"üìÑ Fichier: {file_analysis['file']}")
        print(f"üìä Statut: {file_analysis['status']}")
        
        if file_analysis['status'] == 'success':
            text_info = file_analysis['text_extraction']
            print(f"üìù Texte extrait: {text_info['raw_text_length']} caract√®res")
            print(f"üèÜ Score qualit√©: {text_info['quality_score']:.1f}%")
            
            if file_analysis['potential_issues']:
                print("\n‚ö†Ô∏è  PROBL√àMES D√âTECT√âS:")
                for issue in file_analysis['potential_issues']:
                    print(f"   ‚Ä¢ {issue['description']}")
                    print(f"     ‚Üí {issue['recommendation']}")
            else:
                print("\n‚úÖ Aucun probl√®me d√©tect√©")
    
    # Test qualit√© parsing
    if args.parsing_quality:
        print("\n1Ô∏è‚É£ TEST QUALIT√â PARSING")
        print("-" * 30)
        parsing_results = test_suite.test_cv_parsing_quality(args.cv_folder)
        
        print(f"‚úÖ {parsing_results['successful_parses']}/{parsing_results['tested_files']} fichiers pars√©s avec succ√®s")
        print(f"üìä Qualit√© moyenne: {parsing_results['average_quality']:.1f}%")
    
    print(f"\nüéØ SuperSmartMatch V2.1 Enhanced (Corrig√©) - Tests termin√©s!")

if __name__ == '__main__':
    main()
