#!/bin/bash

# ðŸ”§ Fix du workflow parser - Correction de l'appel des parsers autonomes

echo "ðŸ”§ FIX WORKFLOW PARSER - APPEL DIRECT DES CLASSES"
echo "================================================"

# Corriger l'API CV Parser pour appeler directement la classe FixedPDFParser
echo "ðŸ“ Correction API CV Parser - Appel direct des classes..."
cat > cv-parser-v2/app.py << 'EOF'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ðŸŽ¯ SuperSmartMatch V2 - CV Parser API CORRIGÃ‰ v2
Appel direct des classes de parsers autonomes
"""

import os
import json
import tempfile
import subprocess
import logging
from pathlib import Path
from flask import Flask, request, jsonify

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024

class CVParserV2:
    def __init__(self):
        self.parsers_dir = Path("/app/parsers")
        self.temp_dir = Path("/tmp/cv_parsing")
        self.temp_dir.mkdir(exist_ok=True)
        
        self.fix_pdf_parser = self.parsers_dir / "fix-pdf-extraction.js"
        self.super_parser = self.parsers_dir / "super-optimized-parser.js"
    
    def extract_clean_text(self, pdf_path):
        """Ã‰tape 1 : Extraction du texte propre - APPEL DIRECT"""
        logger.info("ðŸ”§ Extraction texte propre avec appel direct...")
        
        work_dir = self.temp_dir / f"work_{os.getpid()}"
        work_dir.mkdir(exist_ok=True)
        
        # Copier le PDF avec le nom attendu
        work_pdf = work_dir / "input.pdf"
        subprocess.run(['cp', str(pdf_path), str(work_pdf)], check=True)
        
        # CrÃ©er un script wrapper qui appelle directement la classe
        wrapper_script = f"""
const fs = require('fs');
const FixedPDFParser = require('{self.fix_pdf_parser}');

async function extractPDF() {{
    try {{
        const parser = new FixedPDFParser();
        
        console.log('ðŸ”§ DÃ©but extraction PDF...');
        const result = await parser.extractCleanText('input.pdf');
        
        console.log('âœ… Extraction terminÃ©e');
        console.log('ðŸ“„ Fichier:', result.method);
        console.log('ðŸ“Š Longueur:', result.text.length);
        
        // Sauvegarder le rÃ©sultat avec un nom prÃ©visible
        fs.writeFileSync('extracted_text.txt', result.text);
        console.log('ðŸ’¾ Texte sauvegardÃ©: extracted_text.txt');
        
    }} catch (error) {{
        console.error('âŒ Erreur extraction:', error.message);
        process.exit(1);
    }}
}}

extractPDF();
"""
        
        script_file = work_dir / "extract_wrapper.js"
        script_file.write_text(wrapper_script)
        
        result = subprocess.run(
            ['node', str(script_file)],
            cwd=str(work_dir),
            capture_output=True,
            text=True,
            timeout=60
        )
        
        logger.info(f"ðŸ“‹ Extraction stdout: {result.stdout}")
        logger.info(f"ðŸ“‹ Extraction stderr: {result.stderr}")
        
        if result.returncode != 0:
            raise Exception(f"Extraction PDF Ã©chouÃ©e: {result.stderr}")
        
        # Chercher le fichier texte gÃ©nÃ©rÃ©
        text_file = work_dir / "extracted_text.txt"
        if not text_file.exists():
            # Fallback : chercher d'autres fichiers
            text_files = list(work_dir.glob("*_clean_extracted.txt")) + list(work_dir.glob("*.txt"))
            if text_files:
                text_file = text_files[0]
            else:
                raise Exception("Aucun fichier texte gÃ©nÃ©rÃ© par l'extraction")
        
        clean_text = text_file.read_text(encoding='utf-8')
        
        logger.info(f"âœ… Texte extrait: {len(clean_text)} caractÃ¨res")
        return clean_text, str(text_file)
    
    def parse_cv_data(self, text_file_path):
        """Ã‰tape 2 : Parsing du CV - APPEL DIRECT"""
        logger.info("ðŸ§  Parsing CV avec appel direct...")
        
        work_dir = Path(text_file_path).parent
        
        script_content = f"""
const fs = require('fs');
const SuperOptimizedParser = require('{self.super_parser}');

async function parseCV() {{
    try {{
        const parser = new SuperOptimizedParser();
        const text = fs.readFileSync('{text_file_path}', 'utf8');
        
        console.log('ðŸ§  DÃ©but parsing CV...');
        console.log('ðŸ“„ Texte Ã  parser:', text.length, 'caractÃ¨res');
        
        const cvData = parser.parseEnhancedCV(text);
        
        console.log('âœ… Parsing CV terminÃ©');
        console.log('ðŸŽ¯ CompÃ©tences trouvÃ©es:', cvData.skills ? cvData.skills.length : 0);
        console.log('ðŸ‘¤ Nom dÃ©tectÃ©:', cvData.personal_info?.name || 'Non dÃ©tectÃ©');
        
        fs.writeFileSync('cv_parsed_result.json', JSON.stringify(cvData, null, 2));
        console.log(JSON.stringify(cvData, null, 2));
        
    }} catch (error) {{
        console.error('âŒ Erreur parsing CV:', error.message);
        console.error('ðŸ“‹ Stack:', error.stack);
        process.exit(1);
    }}
}}

parseCV();
"""
        
        script_file = work_dir / "parse_cv_script.js"
        script_file.write_text(script_content)
        
        result = subprocess.run(
            ['node', str(script_file)],
            cwd=str(work_dir),
            capture_output=True,
            text=True,
            timeout=30
        )
        
        logger.info(f"ðŸ“‹ Parsing stdout: {result.stdout}")
        logger.info(f"ðŸ“‹ Parsing stderr: {result.stderr}")
        
        if result.returncode != 0:
            raise Exception(f"Parsing CV Ã©chouÃ©: {result.stderr}")
        
        result_file = work_dir / "cv_parsed_result.json"
        if result_file.exists():
            cv_data = json.loads(result_file.read_text())
        else:
            lines = result.stdout.strip().split('\n')
            json_lines = [line for line in lines if line.startswith('{')]
            if json_lines:
                cv_data = json.loads(json_lines[-1])
            else:
                raise Exception("Pas de JSON trouvÃ© dans la sortie")
        
        logger.info(f"âœ… CV parsÃ©: {len(cv_data.get('skills', []))} compÃ©tences")
        return cv_data
    
    def process_cv(self, pdf_file):
        """Workflow complet"""
        logger.info("ðŸš€ Workflow CV complet...")
        
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
            pdf_file.save(temp_pdf.name)
            temp_pdf_path = temp_pdf.name
        
        try:
            clean_text, text_file_path = self.extract_clean_text(temp_pdf_path)
            cv_data = self.parse_cv_data(text_file_path)
            
            cv_data['_metadata'] = {
                'text_length': len(clean_text),
                'processing_status': 'success'
            }
            
            return cv_data
        finally:
            try:
                os.unlink(temp_pdf_path)
            except:
                pass

cv_parser = CVParserV2()

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'service': 'cv-parser-v2',
        'parsers_available': {
            'fix_pdf_extraction': cv_parser.fix_pdf_parser.exists(),
            'super_optimized_parser': cv_parser.super_parser.exists()
        }
    })

@app.route('/api/parse-cv/', methods=['POST'])
def parse_cv():
    logger.info("ðŸ“„ Nouvelle demande parsing CV...")
    
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Aucun fichier fourni'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Nom de fichier vide'}), 400
        
        if not file.filename.lower().endswith('.pdf'):
            return jsonify({'error': 'Seuls les fichiers PDF sont acceptÃ©s'}), 400
        
        cv_data = cv_parser.process_cv(file)
        
        logger.info("âœ… CV parsÃ© avec succÃ¨s")
        return jsonify({
            'status': 'success',
            'data': cv_data
        })
        
    except Exception as e:
        logger.error(f"âŒ Erreur: {str(e)}")
        return jsonify({'error': f'Impossible de parser le CV: {str(e)}'}), 500

if __name__ == '__main__':
    logger.info("ðŸš€ DÃ©marrage CV Parser V2...")
    app.run(host='0.0.0.0', port=5051, debug=False)
EOF

# Corriger l'API Job Parser de la mÃªme maniÃ¨re
echo "ðŸ“ Correction API Job Parser - Appel direct des classes..."
cat > job-parser-v2/app.py << 'EOF'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ðŸŽ¯ SuperSmartMatch V2 - Job Parser API CORRIGÃ‰ v2
Appel direct des classes de parsers autonomes
"""

import os
import json
import tempfile
import subprocess
import logging
from pathlib import Path
from flask import Flask, request, jsonify

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 50 * 1024 * 1024

class JobParserV2:
    def __init__(self):
        self.parsers_dir = Path("/app/parsers")
        self.temp_dir = Path("/tmp/job_parsing")
        self.temp_dir.mkdir(exist_ok=True)
        
        self.fix_pdf_parser = self.parsers_dir / "fix-pdf-extraction.js"
        self.super_parser = self.parsers_dir / "super-optimized-parser.js"
    
    def extract_clean_text(self, pdf_path):
        """Ã‰tape 1 : Extraction du texte propre - APPEL DIRECT"""
        logger.info("ðŸ”§ Extraction texte propre avec appel direct...")
        
        work_dir = self.temp_dir / f"work_{os.getpid()}"
        work_dir.mkdir(exist_ok=True)
        
        # Copier le PDF avec le nom attendu
        work_pdf = work_dir / "input.pdf"
        subprocess.run(['cp', str(pdf_path), str(work_pdf)], check=True)
        
        # CrÃ©er un script wrapper qui appelle directement la classe
        wrapper_script = f"""
const fs = require('fs');
const FixedPDFParser = require('{self.fix_pdf_parser}');

async function extractPDF() {{
    try {{
        const parser = new FixedPDFParser();
        
        console.log('ðŸ”§ DÃ©but extraction PDF...');
        const result = await parser.extractCleanText('input.pdf');
        
        console.log('âœ… Extraction terminÃ©e');
        console.log('ðŸ“„ Fichier:', result.method);
        console.log('ðŸ“Š Longueur:', result.text.length);
        
        // Sauvegarder le rÃ©sultat avec un nom prÃ©visible
        fs.writeFileSync('extracted_text.txt', result.text);
        console.log('ðŸ’¾ Texte sauvegardÃ©: extracted_text.txt');
        
    }} catch (error) {{
        console.error('âŒ Erreur extraction:', error.message);
        process.exit(1);
    }}
}}

extractPDF();
"""
        
        script_file = work_dir / "extract_wrapper.js"
        script_file.write_text(wrapper_script)
        
        result = subprocess.run(
            ['node', str(script_file)],
            cwd=str(work_dir),
            capture_output=True,
            text=True,
            timeout=60
        )
        
        logger.info(f"ðŸ“‹ Extraction stdout: {result.stdout}")
        logger.info(f"ðŸ“‹ Extraction stderr: {result.stderr}")
        
        if result.returncode != 0:
            raise Exception(f"Extraction PDF Ã©chouÃ©e: {result.stderr}")
        
        # Chercher le fichier texte gÃ©nÃ©rÃ©
        text_file = work_dir / "extracted_text.txt"
        if not text_file.exists():
            # Fallback : chercher d'autres fichiers
            text_files = list(work_dir.glob("*_clean_extracted.txt")) + list(work_dir.glob("*.txt"))
            if text_files:
                text_file = text_files[0]
            else:
                raise Exception("Aucun fichier texte gÃ©nÃ©rÃ© par l'extraction")
        
        clean_text = text_file.read_text(encoding='utf-8')
        
        logger.info(f"âœ… Texte extrait: {len(clean_text)} caractÃ¨res")
        return clean_text, str(text_file)
    
    def parse_job_data(self, text_file_path):
        """Ã‰tape 2 : Parsing du Job - APPEL DIRECT"""
        logger.info("ðŸ’¼ Parsing Job avec appel direct...")
        
        work_dir = Path(text_file_path).parent
        
        script_content = f"""
const fs = require('fs');
const SuperOptimizedParser = require('{self.super_parser}');

async function parseJob() {{
    try {{
        const parser = new SuperOptimizedParser();
        const text = fs.readFileSync('{text_file_path}', 'utf8');
        
        console.log('ðŸ’¼ DÃ©but parsing Job...');
        console.log('ðŸ“„ Texte Ã  parser:', text.length, 'caractÃ¨res');
        
        const jobData = parser.parseEnhancedJob(text);
        
        console.log('âœ… Parsing Job terminÃ©');
        console.log('ðŸ’¼ Titre dÃ©tectÃ©:', jobData.job_info?.title || 'Non dÃ©tectÃ©');
        console.log('ðŸ“ Lieu dÃ©tectÃ©:', jobData.job_info?.location || 'Non dÃ©tectÃ©');
        
        fs.writeFileSync('job_parsed_result.json', JSON.stringify(jobData, null, 2));
        console.log(JSON.stringify(jobData, null, 2));
        
    }} catch (error) {{
        console.error('âŒ Erreur parsing Job:', error.message);
        console.error('ðŸ“‹ Stack:', error.stack);
        process.exit(1);
    }}
}}

parseJob();
"""
        
        script_file = work_dir / "parse_job_script.js"
        script_file.write_text(script_content)
        
        result = subprocess.run(
            ['node', str(script_file)],
            cwd=str(work_dir),
            capture_output=True,
            text=True,
            timeout=30
        )
        
        logger.info(f"ðŸ“‹ Parsing stdout: {result.stdout}")
        logger.info(f"ðŸ“‹ Parsing stderr: {result.stderr}")
        
        if result.returncode != 0:
            raise Exception(f"Parsing Job Ã©chouÃ©: {result.stderr}")
        
        result_file = work_dir / "job_parsed_result.json"
        if result_file.exists():
            job_data = json.loads(result_file.read_text())
        else:
            lines = result.stdout.strip().split('\n')
            json_lines = [line for line in lines if line.startswith('{')]
            if json_lines:
                job_data = json.loads(json_lines[-1])
            else:
                raise Exception("Pas de JSON trouvÃ© dans la sortie")
        
        logger.info(f"âœ… Job parsÃ©: {job_data.get('job_info', {}).get('title', 'Titre non dÃ©tectÃ©')}")
        return job_data
    
    def process_job(self, pdf_file):
        """Workflow complet"""
        logger.info("ðŸš€ Workflow Job complet...")
        
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
            pdf_file.save(temp_pdf.name)
            temp_pdf_path = temp_pdf.name
        
        try:
            clean_text, text_file_path = self.extract_clean_text(temp_pdf_path)
            job_data = self.parse_job_data(text_file_path)
            
            job_data['_metadata'] = {
                'text_length': len(clean_text),
                'processing_status': 'success'
            }
            
            return job_data
        finally:
            try:
                os.unlink(temp_pdf_path)
            except:
                pass

job_parser = JobParserV2()

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'service': 'job-parser-v2',
        'parsers_available': {
            'fix_pdf_extraction': job_parser.fix_pdf_parser.exists(),
            'super_optimized_parser': job_parser.super_parser.exists()
        }
    })

@app.route('/api/parse-job', methods=['POST'])
def parse_job():
    logger.info("ðŸ’¼ Nouvelle demande parsing Job...")
    
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'Aucun fichier fourni'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'Nom de fichier vide'}), 400
        
        if not file.filename.lower().endswith('.pdf'):
            return jsonify({'error': 'Seuls les fichiers PDF sont acceptÃ©s'}), 400
        
        job_data = job_parser.process_job(file)
        
        logger.info("âœ… Job parsÃ© avec succÃ¨s")
        return jsonify({
            'status': 'success',
            'data': job_data
        })
        
    except Exception as e:
        logger.error(f"âŒ Erreur: {str(e)}")
        return jsonify({'error': f'Impossible de parser le job: {str(e)}'}), 500

if __name__ == '__main__':
    logger.info("ðŸš€ DÃ©marrage Job Parser V2...")
    app.run(host='0.0.0.0', port=5053, debug=False)
EOF

# Rebuild et redÃ©marrage des services
echo "ðŸ—ï¸ Rebuild des services avec workflow corrigÃ©..."
docker-compose -f docker-compose.v2.yml build

echo "ðŸš€ RedÃ©marrage des services..."
docker-compose -f docker-compose.v2.yml up -d

echo "â³ Attente du dÃ©marrage..."
sleep 20

echo "ðŸ¥ Test health checks..."
curl -s http://localhost:5051/health | jq . || echo "âŒ CV Parser pas prÃªt"
curl -s http://localhost:5053/health | jq . || echo "âŒ Job Parser pas prÃªt"

echo ""
echo "âœ… FIX WORKFLOW TERMINÃ‰!"
echo "======================="
echo ""
echo "ðŸŽ¯ Workflow corrigÃ©:"
echo "   PDF â†’ FixedPDFParser.extractCleanText() â†’ SuperOptimizedParser.parseEnhanced*() â†’ JSON"
echo ""
echo "ðŸ§ª Tests des APIs corrigÃ©es:"
echo "   curl -X POST -F \"file=@cv_christine.pdf\" http://localhost:5051/api/parse-cv/"
echo "   curl -X POST -F \"file=@fdp.pdf\" http://localhost:5053/api/parse-job"
echo ""
echo "ðŸ” Pour dÃ©bugger (logs dÃ©taillÃ©s maintenant):"
echo "   docker-compose -f docker-compose.v2.yml logs -f cv-parser-v2"
echo "   docker-compose -f docker-compose.v2.yml logs -f job-parser-v2"