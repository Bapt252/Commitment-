{
  "dashboard": {
    "id": null,
    "title": "ML Operations Dashboard",
    "tags": ["nexten", "ml", "ai", "operations"],
    "style": "dark",
    "timezone": "browser",
    "editable": true,
    "hideControls": false,
    "graphTooltip": 1,
    "panels": [
      {
        "id": 1,
        "title": "ML Processing Success Rate",
        "type": "stat",
        "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "(sum(rate(ml_requests_total{status=\"success\"}[5m])) / sum(rate(ml_requests_total[5m]))) * 100",
            "legendFormat": "Success Rate %",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "yellow", "value": 90},
                {"color": "green", "value": 95}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "ML Processing Time (95th percentile)",
        "type": "stat",
        "gridPos": {"h": 8, "w": 6, "x": 6, "y": 0},
        "targets": [
          {
            "expr": "histogram_quantile(0.95, sum(rate(ml_processing_duration_seconds_bucket[5m])) by (le))",
            "legendFormat": "95th percentile",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "s",
            "min": 0,
            "thresholds": {
              "steps": [
                {"color": "green", "value": 0},
                {"color": "yellow", "value": 10},
                {"color": "red", "value": 30}
              ]
            }
          }
        }
      },
      {
        "id": 3,
        "title": "OpenAI API Calls",
        "type": "stat",
        "gridPos": {"h": 8, "w": 6, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "sum(rate(openai_api_calls_total[5m]))",
            "legendFormat": "Calls/sec",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "reqps",
            "min": 0
          }
        }
      },
      {
        "id": 4,
        "title": "OpenAI Tokens Used (per hour)",
        "type": "stat",
        "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0},
        "targets": [
          {
            "expr": "sum(rate(openai_tokens_total[1h]))",
            "legendFormat": "Tokens/hour",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "short",
            "min": 0
          }
        }
      },
      {
        "id": 5,
        "title": "ML Operations by Service",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "targets": [
          {
            "expr": "sum(rate(ml_requests_total[5m])) by (service, operation)",
            "legendFormat": "{{service}} - {{operation}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "reqps",
            "min": 0
          }
        }
      },
      {
        "id": 6,
        "title": "ML Processing Duration",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(ml_processing_duration_seconds_bucket[5m])) by (le, service))",
            "legendFormat": "50th percentile - {{service}}",
            "refId": "A"
          },
          {
            "expr": "histogram_quantile(0.95, sum(rate(ml_processing_duration_seconds_bucket[5m])) by (le, service))",
            "legendFormat": "95th percentile - {{service}}",
            "refId": "B"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "s",
            "min": 0
          }
        }
      },
      {
        "id": 7,
        "title": "ML Error Distribution",
        "type": "piechart",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 16},
        "targets": [
          {
            "expr": "sum(rate(ml_errors_total[5m])) by (error_type)",
            "legendFormat": "{{error_type}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "short"
          }
        }
      },
      {
        "id": 8,
        "title": "OpenAI Model Usage",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 16},
        "targets": [
          {
            "expr": "sum(rate(openai_api_calls_total[5m])) by (model)",
            "legendFormat": "{{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "reqps",
            "min": 0
          }
        }
      },
      {
        "id": 9,
        "title": "Token Usage by Type",
        "type": "timeseries",
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24},
        "targets": [
          {
            "expr": "sum(rate(openai_tokens_total[5m])) by (type, model)",
            "legendFormat": "{{type}} - {{model}}",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"},
            "unit": "short",
            "min": 0
          }
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "timepicker": {
      "refresh_intervals": ["5s", "10s", "30s", "1m", "5m", "15m", "30m", "1h", "2h", "1d"],
      "time_options": ["5m", "15m", "1h", "6h", "12h", "24h", "2d", "7d", "30d"]
    },
    "refresh": "30s",
    "schemaVersion": 27,
    "version": 1
  }
}