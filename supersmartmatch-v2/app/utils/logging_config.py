"""
Configuration du logging pour SuperSmartMatch V2

Configure le systÃ¨me de logging avec :
- Niveaux de log configurables
- Formatage JSON structurÃ©
- Rotation des logs
- MÃ©triques intÃ©grÃ©es
"""

import logging
import logging.handlers
import sys
import json
from datetime import datetime
from typing import Dict, Any
from pathlib import Path


class JSONFormatter(logging.Formatter):
    """
    Formateur JSON pour les logs structurÃ©s
    """
    
    def format(self, record: logging.LogRecord) -> str:
        """Formate un enregistrement de log en JSON"""
        
        # DonnÃ©es de base
        log_data = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        # Ajouter des champs spÃ©ciaux s'ils existent
        if hasattr(record, 'request_id'):
            log_data['request_id'] = record.request_id
        
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        
        if hasattr(record, 'algorithm'):
            log_data['algorithm'] = record.algorithm
        
        if hasattr(record, 'duration_ms'):
            log_data['duration_ms'] = record.duration_ms
        
        if hasattr(record, 'service'):
            log_data['service'] = record.service
        
        # Exception si prÃ©sente
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
        
        # DonnÃ©es additionnelles
        if hasattr(record, 'extra_data'):
            log_data.update(record.extra_data)
        
        return json.dumps(log_data, ensure_ascii=False)


class SuperSmartMatchFilter(logging.Filter):
    """
    Filtre personnalisÃ© pour les logs SuperSmartMatch
    """
    
    def filter(self, record: logging.LogRecord) -> bool:
        """Filtre les logs selon les critÃ¨res"""
        
        # Ajouter des mÃ©tadonnÃ©es standard
        record.service = "supersmartmatch-v2"
        record.version = "2.0.0"
        
        # Filtrer les logs de sanity check trop verbeux
        if record.levelno == logging.DEBUG and "health" in record.getMessage().lower():
            return False
        
        return True


def setup_logging(log_level: str = "INFO", enable_json: bool = True, log_file: str = None):
    """
    Configure le systÃ¨me de logging
    
    Args:
        log_level: Niveau de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        enable_json: Activer le formatage JSON
        log_file: Fichier de log (optionnel)
    """
    
    # Configuration de base
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level.upper()))
    
    # Supprimer les handlers existants
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # Handler console
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(getattr(logging, log_level.upper()))
    
    # Formateur
    if enable_json:
        formatter = JSONFormatter()
    else:
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
    
    console_handler.setFormatter(formatter)
    
    # Filtre personnalisÃ©
    supersmartmatch_filter = SuperSmartMatchFilter()
    console_handler.addFilter(supersmartmatch_filter)
    
    root_logger.addHandler(console_handler)
    
    # Handler fichier avec rotation (si spÃ©cifiÃ©)
    if log_file:
        # CrÃ©er le rÃ©pertoire si nÃ©cessaire
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=10 * 1024 * 1024,  # 10 MB
            backupCount=5
        )
        file_handler.setLevel(getattr(logging, log_level.upper()))
        file_handler.setFormatter(formatter)
        file_handler.addFilter(supersmartmatch_filter)
        
        root_logger.addHandler(file_handler)
    
    # Configuration spÃ©cifique pour certains loggers
    _configure_specific_loggers(log_level)
    
    # Log initial
    logger = logging.getLogger(__name__)
    logger.info(
        f"ğŸ”§ Logging configurÃ© - Niveau: {log_level}, JSON: {enable_json}, Fichier: {log_file or 'Non'}"
    )


def _configure_specific_loggers(log_level: str):
    """Configure des loggers spÃ©cifiques"""
    
    # Logger aiohttp moins verbeux
    aiohttp_logger = logging.getLogger('aiohttp')
    aiohttp_logger.setLevel(logging.WARNING)
    
    # Logger Redis moins verbeux
    redis_logger = logging.getLogger('aioredis')
    redis_logger.setLevel(logging.WARNING)
    
    # Logger uvicorn personnalisÃ©
    uvicorn_logger = logging.getLogger('uvicorn')
    if log_level.upper() == 'DEBUG':
        uvicorn_logger.setLevel(logging.DEBUG)
    else:
        uvicorn_logger.setLevel(logging.INFO)
    
    # Logger pour les accÃ¨s HTTP
    access_logger = logging.getLogger('uvicorn.access')
    access_logger.setLevel(logging.INFO)


def get_logger_with_context(name: str, **context) -> logging.LoggerAdapter:
    """
    CrÃ©e un logger avec contexte additionnel
    
    Args:
        name: Nom du logger
        **context: Contexte additionnel (request_id, user_id, etc.)
    
    Returns:
        LoggerAdapter avec contexte
    """
    logger = logging.getLogger(name)
    return logging.LoggerAdapter(logger, context)


class MetricsLogHandler(logging.Handler):
    """
    Handler spÃ©cialisÃ© pour les mÃ©triques
    
    Extrait et envoie les mÃ©triques depuis les logs vers un systÃ¨me de monitoring
    """
    
    def __init__(self, metrics_callback=None):
        super().__init__()
        self.metrics_callback = metrics_callback
        self.metrics_buffer = []
    
    def emit(self, record: logging.LogRecord):
        """Traite un enregistrement de log pour extraire les mÃ©triques"""
        try:
            # Extraire les mÃ©triques depuis les logs
            if hasattr(record, 'duration_ms'):
                metric = {
                    'timestamp': datetime.utcnow().isoformat(),
                    'type': 'duration',
                    'value': record.duration_ms,
                    'tags': {
                        'service': getattr(record, 'service', 'unknown'),
                        'algorithm': getattr(record, 'algorithm', 'unknown'),
                        'level': record.levelname
                    }
                }
                
                if self.metrics_callback:
                    self.metrics_callback(metric)
                else:
                    self.metrics_buffer.append(metric)
        
        except Exception:
            # Ne pas faire Ã©chouer le logging si les mÃ©triques posent problÃ¨me
            pass
    
    def get_buffered_metrics(self) -> list:
        """RÃ©cupÃ¨re et vide le buffer de mÃ©triques"""
        metrics = self.metrics_buffer.copy()
        self.metrics_buffer.clear()
        return metrics


# Helpers pour logging structurÃ©
def log_matching_request(logger: logging.Logger, algorithm: str, num_jobs: int, duration_ms: float, success: bool):
    """Log structurÃ© pour les requÃªtes de matching"""
    logger.info(
        f"{'âœ…' if success else 'âŒ'} Matching request completed",
        extra={
            'algorithm': algorithm,
            'num_jobs': num_jobs,
            'duration_ms': duration_ms,
            'success': success,
            'event_type': 'matching_request'
        }
    )


def log_algorithm_selection(logger: logging.Logger, selected: str, score: float, reasons: list):
    """Log structurÃ© pour la sÃ©lection d'algorithme"""
    logger.info(
        f"ğŸ§  Algorithm selected: {selected}",
        extra={
            'selected_algorithm': selected,
            'selection_score': score,
            'selection_reasons': reasons,
            'event_type': 'algorithm_selection'
        }
    )


def log_service_health(logger: logging.Logger, service: str, status: str, details: dict):
    """Log structurÃ© pour la santÃ© des services"""
    status_emoji = {
        'healthy': 'âœ…',
        'unhealthy': 'âŒ', 
        'degraded': 'âš ï¸',
        'unknown': 'â“'
    }
    
    logger.info(
        f"{status_emoji.get(status, 'â“')} Service {service}: {status}",
        extra={
            'service_name': service,
            'health_status': status,
            'health_details': details,
            'event_type': 'service_health'
        }
    )


def log_circuit_breaker_event(logger: logging.Logger, service: str, old_state: str, new_state: str, failure_count: int):
    """Log structurÃ© pour les Ã©vÃ©nements circuit breaker"""
    state_emoji = {
        'closed': 'ğŸŸ¢',
        'open': 'ğŸ”´',
        'half_open': 'ğŸŸ¡'
    }
    
    logger.warning(
        f"{state_emoji.get(new_state, 'â“')} Circuit breaker {service}: {old_state} â†’ {new_state}",
        extra={
            'service_name': service,
            'old_state': old_state,
            'new_state': new_state,
            'failure_count': failure_count,
            'event_type': 'circuit_breaker_transition'
        }
    )
